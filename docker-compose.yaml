version: '2'

services:
  kafka1:
    image: confluentinc/cp-kafka:latest
    container_name: kafka1
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"
      KAFKA_LOG_CLEANUP_POLICY: delete  # Set log cleanup policy to delete
      KAFKA_LOG_RETENTION_MINUTES: 4
      KAFKA_TRANSACTION_REMOVE_EXPIRED_TRANSACTION_CLEANUP_INTERVAL_MS: 12000
    ports:
      - "9092:9092"
      - "9093:9093"

  kafka2:
    image: confluentinc/cp-kafka:latest
    container_name: kafka2
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 2
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"
      KAFKA_LOG_CLEANUP_POLICY: delete  # Set log cleanup policy to delete
      KAFKA_LOG_RETENTION_MINUTES: 4
      KAFKA_TRANSACTION_REMOVE_EXPIRED_TRANSACTION_CLEANUP_INTERVAL_MS: 12000
    ports:
      - "9094:9092"
      - "9095:9093"

  kafka3:
    image: confluentinc/cp-kafka:latest
    container_name: kafka3
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 3
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"
      KAFKA_LOG_CLEANUP_POLICY: delete  # Set log cleanup policy to delete
      KAFKA_LOG_RETENTION_MINUTES: 4
      KAFKA_TRANSACTION_REMOVE_EXPIRED_TRANSACTION_CLEANUP_INTERVAL_MS: 12000
    ports:
      - "9096:9092"
      - "9097:9093"

  kafka4:
    image: confluentinc/cp-kafka:latest
    container_name: kafka4
    environment:
      KAFKA_PROCESS_ROLES: broker
      KAFKA_NODE_ID: 4
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka4:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"
      KAFKA_LOG_CLEANUP_POLICY: delete  # Set log cleanup policy to delete
      KAFKA_LOG_RETENTION_MINUTES: 4
      KAFKA_TRANSACTION_REMOVE_EXPIRED_TRANSACTION_CLEANUP_INTERVAL_MS: 12000
    ports:
      - "9098:9092"

  kafka5:
    image: confluentinc/cp-kafka:latest
    container_name: kafka5
    environment:
      KAFKA_PROCESS_ROLES: broker
      KAFKA_NODE_ID: 5
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka5:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"
      KAFKA_LOG_CLEANUP_POLICY: delete  # Set log cleanup policy to delete
      KAFKA_LOG_RETENTION_MINUTES: 4
      KAFKA_TRANSACTION_REMOVE_EXPIRED_TRANSACTION_CLEANUP_INTERVAL_MS: 12000
    ports:
      - "9099:9092"
  
  kafka-init-topics:
    image: confluentinc/cp-kafka:latest
    command: [ "/bin/bash", "-c", "/create_topic.sh"]
    volumes:
      - type: bind
        source: ./producer/create_topic.sh
        target: /create_topic.sh
    depends_on:
      kafka1:
        condition: service_started
    init: true


  producer:
    build: ./producer
    depends_on:
      - kafka-init-topics
      - kafka1
      - kafka2
      - kafka3
      - kafka4
      - kafka5
    volumes:
      - ./producer/data:/app/data

  timescaledb:
    build:
      context: ./database
    environment:
      - POSTGRES_PASSWORD=password
      - POSTGRES_USER=postgres
      - POSTGRES_DB=stocksdb
    ports:
      - "5433:5432"
    volumes:
      - ./database:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  python-db-helper:
    build:
      context: ./python-db-helper
    depends_on:
      timescaledb:
        condition: service_healthy
    environment:
      - DB_HOST=timescaledb
      - DB_PORT=5432
      - DB_USER=postgres
      - DB_PASS=password
      - DB_NAME=stocksdb
    volumes:
      - ./python-db-helper:/app
    command: ["python", "populate_stocks.py"]

  fastapi:
     build:
       context: ./timescale-fastapi
     depends_on:
       timescaledb:
         condition: service_healthy
     environment:
       - DB_HOST=timescaledb
       - DB_PORT=5432
       - DB_USER=postgres
       - DB_PASS=password
       - DB_NAME=stocksdb
     ports:
       - "8000:8000"
     volumes:
       - ./timescale-fastapi:/usr/app
     command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

  jobmanager:
    image: flink:1.20-scala_2.12
    build: ./consumer
    hostname: "jobmanager"
    expose:
      - "6123"
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager  
    volumes:
      - ./consumer/flink_job.py:/opt/flink_job.py  
  taskmanager:
    image: flink:1.20-scala_2.12
    depends_on:
      - jobmanager
    command: taskmanager
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 6  
    volumes:
      - ./consumer/flink_job.py:/opt/flink_job.py

  redis:
    image: redis:alpine
    ports:
      - 6379:6379
  
  grafana:
    image: grafana/grafana:10.0.2
    ports:
      - "3000:3000"
    volumes:
      - ./frontend/provisioning:/etc/grafana/provisioning
      - ./frontend/Financial Data Analysis.json:/etc/grafana/provisioning/dashboards/dashboard.json
    environment:
      - GF_INSTALL_PLUGINS=yesoreyeram-infinity-datasource
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_DATE_FORMATS_FULL_DATE=YYYY-MM-DD HH:mm:ss.SSS
      - GF_DASHBOARDS_MIN_REFRESH_INTERVAL=1s